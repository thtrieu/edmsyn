{
    "contents" : "#=======================+\n# Sub-Routine functions |\n#=======================+\n\n\n#' @export\nprint.context <- function(x){\n  cat(\"Activated units in the context:\\n\")\n  print(names(x)[which(sapply(x,is.null)==0)])\n}\n\n#' @export\ntoStr <- function(x, max){\n  if (max<10) r <- toString(x)\n  else\n    r <- (paste0(paste(sapply(1:log(max,10),function(x)\"0\"),collapse=\"\"),x))\n  return(paste0(\"0\",r))\n}\n\n#' @export\nwhich.closest <- function(target, candidates){\n  ref <- STRUCTURE[[target]][[1]]\n  which.max(\n    sapply(candidates, function(c){\n      sum(sapply(c,function(x){x %in% ref}))\n    }))\n}\n\n#' @export\ncompat <- function(val,tel){\n  if (class(tel) == \"min\") return(all(tel <= val))\n  if (class(tel) == \"max\") return(all(tel >= val))\n  if (class(tel) == \"numeric\") return(max(abs(val-tel)) < 1e-10)\n  else return(identical(val,tel))\n}\n\n#===========+\n# STRUCTURE |\n#===========+\n\n#' This function is the shit.\n#'\n#' @importFrom CDM sim.din\n#' @importFrom CDM din\n#' @importFrom stats optim\n#' @importFrom MASS ginv\n#' @importFrom HMM initHMM\n#' @importFrom HMM baumWelch\nassemble.structure <- function(){\n  #================+\n  # Core functions |\n  #================+\n  genQUniform <- function(concepts, perItem) {\n    c <- combn(concepts,perItem)\n    items <- ncol(c)\n    Q = matrix(0,items,concepts)\n    for (i in 1:items)\n      Q[i,c[,i]] <- 1\n    return(Q)\n  }\n  genQMax <- function(concepts, maxPerItem) {\n    Q <- NULL\n    for (i in 1:maxPerItem)\n      Q <- rbind(Q,genQUniform(concepts,i))\n    return(Q)\n  }\n  genQRand <- function(items, concepts) {\n    sampleFrom <- NULL\n    replace <- TRUE\n    #------------CISAC--------------------------------------\n    if (is.null(sampleFrom)) {\n      if (is.null(concepts))\n        stop(\"Input Insufficiency\")\n      else\n        sampleFrom <- genQMax(concepts,concepts)\n    }\n    else{\n      if (!is.null(concepts) & concepts != ncol(sampleFrom))\n        stop(\"Input Conflict\")\n    }\n\n    #------------GENERATING---------------------------------\n    Q <- as.matrix(sampleFrom[sample(x = 1:nrow(sampleFrom),\n                                     size = items,\n                                     replace = replace),])\n    if (items == 1) Q <- t(Q)\n    return(Q)\n  }\n  maxCombn <- function(n){cbind(rep(0,n),t(genQMax(n,n)))}\n  randGen <- function(P) {\n    matrix(sapply(P,\n                  function(i) {\n                    sample(0:1, 1, prob = c(1 - i,i))\n                  }),\n           nrow(P),\n           ncol(P))\n  }\n  depth <- function(root, poks) {\n    level <- 1\n    items <- nrow(poks)\n    poks_ <- poks\n    while (rowSums(poks_)[root] > 0) {\n      level = level + 1\n      poks_ = poks_ %*% poks\n      if (level == items) break\n    }\n    return(level)\n  }\n  PToOdds <- function(p) p/(1-p)\n  OddsToP <- function(o) o/(1+o)\n  binaryHMMLearn <- function(R){\n    time <- length(R)\n    observe <- as.character(R)\n\n    learn <- NULL\n    while(class(learn) != \"list\"){\n      # Initizalizing\n      states <- c(\"0\",\"1\")\n      symbols <- c(\"0\",\"1\")\n      pi <- runif(1,0,1) # p(z_1 = 0)\n      pi <- c(pi,1-pi)\n      A <- c(runif(1,0,1),0) # Transition prob\n      A <- matrix(c(A,1-A),2,2) # A[i,j] = p(zn+1=j-1|zn=i-1)\n      E <- runif(2,0,1) # Emission prob\n      E <- matrix(c(E,1-E),2,2) # E[i,j] = p(x=j-1|z=i-1)\n      hmm <- initHMM(states, symbols, pi, A, E)\n      learn <- try(baumWelch(hmm = hmm, observation = observe)$hmm,TRUE)\n    }\n    names(learn$startProbs) <- NULL\n    returns <- list(learn$startProbs[2],learn$transProbs[1,2],\n                    learn$emissionProbs[2,1],learn$emissionProbs[1,2])\n    names(returns) <- c(\"probInitS\",\"L\",\"slip\",\"guess\")\n    return(returns)\n  }\n  nmfLearn <- function(R, concepts, func){\n    Q <- genQRand(nrow(R), concepts)\n    S <- matrix(0,concepts, ncol(R))\n\n    space <- genQMax(concepts,concepts)\n    space <- space[sample(1:nrow(space)),]\n    space0 <- cbind( t(space), rep(0,concepts) )\n\n    learnS <- function(){\n      ref <- R[,iS]\n      predict <- func(Q = Q, S = space0)\n      distance <- colSums((predict - ref)^2)\n      best <- which.min(distance)[1]\n      space0[,best]\n    }\n\n    learnQ <- function(){\n      ref <- R[iQ,]\n      predict <- func(Q = space, S = S)\n      distance <- colSums((t(predict) - ref)^2)\n      best <- which.min(distance)[1]\n      t(space[best,])\n    }\n\n\n    hault <- 0\n    threshold <- max(nrow(Q), ncol(S))\n    permS <- sample(ncol(S))\n    permQ <- sample(nrow(Q))\n\n    for (i in 1:1000){\n      idS <- (i-1) %% ncol(S) + 1\n      idQ <- (i-1) %% nrow(Q) + 1\n      if (idS == 1) permS <- sample(ncol(S))\n      if (idQ == 1) permQ <- sample(nrow(Q))\n      iS <- permS[idS]\n      iQ <- permQ[idQ]\n\n      lS <- learnS()\n      lQ <- learnQ()\n\n      progress = any(S[,iS]!=lS) | any(Q[iQ,]!=lQ)\n      if (progress == TRUE) hault <- 0\n      else hault <- hault + 1\n      if (hault == threshold) break\n\n      S[,iS] <- learnS()\n      Q[iQ,] <- learnQ()\n    }\n\n    returns <- list(Q, S)\n    names(returns) <- c(\"Q\",\"S\")\n    return(returns)\n  }\n  QSAvgGenR2 <- function(Q, S){\n    (Q/rowSums(Q))%*%(S^2)\n  }\n\n  expGen <- function(st.exp, it.exp) {\n    dif <- it.exp\n    abi <- st.exp\n    dif[dif == 1] <- 2\n    abi[abi == 1] <- 2\n    difOdd <- PToOdds(dif)\n    abiOdd <- PToOdds(abi)\n    POdd <- difOdd %*% t(abiOdd)\n    P <- OddsToP(POdd)\n    P[which(difOdd < 0),] <- 1\n    P[,which(abiOdd < 0)] <- 1\n    list(R=randGen(P = P))\n  }\n  logitGen <- function(dis, dif, abi){\n    t <- abi\n    a <- -dis\n    b <- dis*dif\n    u <- rep(1,length(t))\n    list(R=randGen(1/(1+exp(a%*%t(t)+b%*%t(u)))))\n  }\n  dinaGen <- function(Q,M,slip,guess) {\n    R  <- t(sim.din(\n      q.matrix = Q,\n      guess = guess,\n      slip = slip,\n      rule = \"DINA\",\n      alpha = t(M)\n    )$dat)\n    rownames(R) <- NULL\n    list(R=R, Q=Q)\n  }\n  dinoGen <- function(Q,M,slip,guess) {\n    R  <- t(sim.din(\n      q.matrix = Q,\n      guess = guess,\n      slip = slip,\n      rule = \"DINO\",\n      alpha = t(M)\n    )$dat)\n    rownames(R) <- NULL\n    list(R=R,Q=Q)\n  }\n  QMConGen <- function(Q, M){\n    list(R=(0 + !(Q%*%(1-M))), concepts = nrow(M))\n  }\n  QMDisGen <- function(Q, M){\n    list(R = (1 - !(Q%*%M)), concepts = nrow(M))\n  }\n  QMComGen <- function(Q, M){\n    list(R=randGen((Q/rowSums(Q)) %*% M), concepts = nrow(M))\n  }\n  #QSLinPesGen <- function(Q,S){P<-sapply(1:ncol(S),function(s){sapply(1:nrow(Q),function(i){min((Q[i,]*S[,s])[(Q[i,])>0])})});list(R=randGen(P=P),concepts=nrow(S))}\n  QSLinAvgGen<- function(Q,S){\n    list(R=randGen(sqrt(QSAvgGenR2(Q = Q,S = S))), concepts = nrow(S))\n  }\n  Gen.Synthetic.POKS <- function(St.Var, Students, State, OR.t, OR.f, PO, alpha.c, alpha.p, p.min){\n    PO <- PO$ks\n    Items <- length(State)\n    if(St.Var>0.3) stVar <- 0.3\n    if(St.Var<0) stVar <- 0\n    R = matrix(-1,Students,Items)\n    for(i in 1:Students)\n    {\n      #Create Samples\n      for(it in 1:ncol(R))\n      {\n        R[i,it] <- sample(0:1,size = 1,prob = c(1- OddsToP(State[it]),OddsToP(State[it])))\n        #Odds.temp.state[k] <- ks.update(i,RG[j,i],ks$state,ks)[k]\n        if(R[i,it]==1)\n        {\n          for(k in which(PO[it,]==1)){\n            State[k] <- State[k]*OR.t[k,it]\n          }\n        }else{\n          for(k in which(PO[,it]==1)){\n            State[k] <- State[k]*OR.f[k,it]\n          }\n        }\n      }\n    }\n\n    list(R=t(R), alpha.c = alpha.c, alpha.p = alpha.p, p.min = p.min)\n  }\n  poksGen <- function(students, poks, successRate, alpha.c, alpha.p, p.min){\n    poks <- poks$ks\n    items <- nrow(poks)\n    poks_ <- poks\n    R <- matrix(-1,items,students)\n\n    #Initiate result for root nodes and their children\n    while (any(poks_ == 1)) {\n      root <- intersect(which(rowSums(poks_) != 0),\n                        which(colSums(poks_) == 0))[1]\n      # Root: at least one child and no parents\n\n      difficulty = depth(root, poks)\n      R[root,which(R[root,] < 0)] <-\n        sample(\n          0:1,-sum(R[root,which(R[root,] < 0)]),\n          prob = c(1 - 1 / difficulty, 1 / difficulty),\n          replace = TRUE\n        )\n      R[which(poks_[root,] == 1),which(R[root,] == 1)] <- 1\n      poks_[root,] <- 0\n    }\n\n    # Initiate the rest\n    while (any(R < 0)) {\n      root = which(rowSums(R < 0) > 0)[1]\n      R[root,which(R[root,] < 0)] <-\n        sample(0:1,-sum(R[root,which(R[root,] < 0)]),\n               prob = c(1 - successRate, successRate),\n               replace = TRUE)\n    }\n\n    # 2-generation Incremental fitting the successRate param\n    tol <- 0.01\n    twoSteps <- poks %*% poks\n    while (abs(mean(R) - successRate) > tol) {\n      flip <- mean(R) < successRate\n      choose = sample(which(R != flip))[1]\n      item <- row(R)[choose]\n      student <- col(R)[choose]\n      R[item,student] <- flip\n      copy <- twoSteps\n      if (flip == 0)\n        copy <- t(copy)\n      follows <- which(copy[item,] > 0)\n      R[follows,student] <- flip\n    }\n\n    list(R=R, alpha.c = alpha.c, alpha.p = alpha.p, p.min = p.min)\n  }\n  skillBktGen <- function(initS, L, slip, guess, time, order, perItem){\n    items <- nrow(initS)\n    concepts <- items\n    students <- ncol(L)\n    Q <- diag(items)\n    model = \"dina\"\n\n    learn <- function(state, trans) {\n      newState <- randGen(P = trans)\n      newState[state == 1] <- 1\n      return(newState)\n    }\n\n    R <- array(0,dim = c(items,students,time))\n    RPerItem <- matrix(0,time,students)\n    M <- array(0,dim = c(concepts,students,time))\n    M[,,1] <- initS\n\n    Q.ori <- Q\n    slip.ori <- slip\n    guess.ori <- guess\n\n    for (i in 1:time) {\n      if (perItem == TRUE) {\n        Q <- t(as.matrix(Q.ori[order[i],]))\n        slip <- slip.ori[order[i],]\n        guess <- guess.ori[order[i],]\n      }\n      if (model == \"nmf.com\")\n        r <- QMComGen(Q = Q,S = M[,,i])\n      else{\n        r <- NULL\n        Mi <- M[,,i]\n        for (j in 1:students){\n          Mij <- as.matrix(Mi[,j])\n          if (model == \"dina\")\n            r_ <- dinaGen(\n              Q = Q,M = Mij, slip = slip[j],guess = guess[j]\n            )$R\n          else\n            r_ <- dinoGen(\n              Q = Q,M = Mij, slip = slip[j],guess = guess[j]\n            )$R\n          r <- cbind(r,r_)\n        }\n      }\n      if (perItem == TRUE)\n        RPerItem[i,] <- r\n      else\n        R[,,i] <- r\n      if (i < time)\n        M[,,(i + 1)] <- learn(state = M[,,i], trans = L)\n    }\n\n    if (perItem == TRUE)\n      R <- RPerItem\n    if (perItem == FALSE)\n      order <- NULL\n    list(R=R, order = order)\n  }\n  qBktGen <- function(initS, L, slip, guess, time, order, perItem, Q, model){\n    items <- nrow(Q)\n    concepts <- ncol(Q)\n    students <- ncol(initS)\n\n    learn <- function(state, trans) {\n      newState <- randGen(P = trans)\n      newState[state == 1] <- 1\n      return(newState)\n    }\n\n    R <- array(0,dim = c(items,students,time))\n    RPerItem <- matrix(0,time,students)\n    M <- array(0,dim = c(concepts,students,time))\n    M[,,1] <- initS\n\n    Q.ori <- Q\n    slip.ori <- slip\n    guess.ori <- guess\n\n    for (i in 1:time) {\n      if (perItem == TRUE) {\n        Q <- t(as.matrix(Q.ori[order[i],]))\n        slip <- slip.ori[order[i],]\n        guess <- guess.ori[order[i],]\n      }\n      if (model == \"nmf.com\")\n        r <- QMComGen(Q = Q,S = M[,,i])\n      else{\n        r <- NULL\n        Mi <- M[,,i]\n        for (j in 1:students){\n          Mij <- as.matrix(Mi[,j])\n          if (model == \"dina\")\n            r_ <- dinaGen(\n              Q = Q,M = Mij, slip = slip[j],guess = guess[j]\n            )$R\n          else\n            r_ <- dinoGen(\n              Q = Q,M = Mij, slip = slip[j],guess = guess[j]\n            )$R\n          r <- cbind(r,r_)\n        }\n      }\n      if (perItem == TRUE)\n        RPerItem[i,] <- r\n      else\n        R[,,i] <- r\n      if (i < time)\n        M[,,(i + 1)] <- learn(state = M[,,i], trans = L)\n    }\n\n    if (perItem == TRUE)\n      R <- RPerItem\n    if (perItem == FALSE)\n      order <- NULL\n    list(R=R, order = order)\n  }\n  po2State <- function(PO){\n    PO <- PO$ks\n    Items <- nrow(PO)\n    Get.Ks.State <- function(Node,PO,State)\n    {\n      if(sum(PO[,Node])==0) {res = 0} else\n      {res = max(State[which(PO[,Node]==1)])}\n      level = depth(Node,PO)\n      return(runif(1,res,res+((1-res)/level)))\n    }\n    State = rep(0,Items)\n    for (j in 1:Items){\n      State[j] = Get.Ks.State(j,PO,State)\n    }\n    State <- PToOdds(State)\n  }\n  stVarPo2Ort <- function(stVar, PO){\n    PO <- PO$ks\n    Items <- nrow(PO)\n    OR.t = matrix(0.5,Items,Items)\n    OR.t[which(t(PO)==1)] <- runif(sum(PO),0.8-stVar,1)\n    OR.t <- PToOdds(OR.t)\n  }\n  stVarPo2Orf <- function(stVar, PO){\n    PO <- PO$ks\n    Items <- nrow(PO)\n    OR.f = matrix(0.5,Items,Items)\n    OR.f[which(t(PO)==1)] <- runif(sum(PO),0,0.2+stVar)\n    OR.f <- PToOdds(OR.f)\n  }\n  genPoks <- function(items, minTrees, maxTrees, minDepth, maxDepth,\n                      density, minItemPerTree, maxItemPerTree) {\n    treeSizes <- NULL\n    treeDepths <- NULL\n    #-------------CISAC------------------------------------------------------\n    if (!is.null(treeSizes) &\n        !is.null(treeDepths) &\n        length(treeSizes) != length(treeDepths))\n      stop(\"Input Conflict\")\n    if (minDepth + 1 > maxItemPerTree)\n      stop(\"Requirements cannot be satisfied\")\n    if (items < minTrees * minItemPerTree |\n        items > maxTrees * maxItemPerTree)\n      stop(\"Requirements cannot be satisfied\")\n\n    #-------------GENERATING-------------------------------------------------\n\n    trees <- length(treeSizes)\n    if (is.null(treeSizes)) {\n      # pick a number of trees\n      lowerTrees <- max(minTrees,ceiling(items / maxItemPerTree))\n      upperTrees <-\n        min(maxTrees,floor(items / max(minDepth + 1,minItemPerTree)))\n      if (lowerTrees > upperTrees)\n        stop(\"Requirements cannot be satisfied\")\n      if (!is.null(treeDepths)) {\n        if (length(treeDepths) < lowerTrees |\n            length(treeDepths) > upperTrees)\n          stop(\"Requirements cannot be satisfied\")\n        else\n          trees <- length(treeDepths)\n      }\n      else{\n        if (lowerTrees == upperTrees)\n          trees <- lowerTrees\n        else\n          trees <- sample(lowerTrees:upperTrees,1)\n      }\n\n      # get the numbers of item on each tree\n      sampleTree <- function(itemsLeft, x) {\n        if (x == 1)\n          return(itemsLeft)\n\n        lower <- itemsLeft - maxItemPerTree * (x - 1)\n        upper <-\n          itemsLeft - max(minDepth + 1,minItemPerTree) * (x - 1)\n        if (lower > maxItemPerTree)\n          stop(\"Requirements cannot be satisfied\")\n        if (upper < minItemPerTree)\n          stop(\"Requirements cannot be satisfied\")\n\n        upper <- min(upper,maxItemPerTree)\n        if (upper < minDepth)\n          stop(\"Requirements cannot be satisfied\")\n        lower <- max(lower,minItemPerTree,minDepth + 1)\n        if (!is.null(treeDepths))\n          lower <- max(lower, treeDepths[trees - x + 1] + 1)\n\n\n        if (lower > upper)\n          stop(\"Requirements cannot be satisfied\")\n        if (lower == upper)\n          sampleResult <- lower\n        else\n          sampleResult <- sample(x = lower:upper,1)\n\n        c(sampleResult,c(sampleTree(itemsLeft - sampleResult,x - 1)))\n      }\n\n      #permute to remove bias from ordered sampling\n      perm <- sample(trees)\n      treeSizes <- sampleTree(items,trees)[perm]\n      if (!is.null(treeDepths))\n        treeDepths <- treeDepths[perm]\n    }\n\n    if (!is.null(treeDepths)) {\n      if (sum((treeDepths + 1) > treeSizes) > 0)\n        stop(\"Requirements cannot be satisfied\")\n    }\n    else{\n      treeDepths <- numeric(trees)\n      for (i in 1:trees) {\n        upperDepth <- min(maxDepth, treeSizes[i] - 1)\n        if (minDepth == upperDepth)\n          treeDepths[i] <- minDepth\n        else\n          if (treeSizes[i] == 1)\n            treeDepths[i] <- 0\n          else\n            treeDepths[i] <- sample(max(minDepth,1):upperDepth,1)\n      }\n    }\n\n    #permute to remove bias from ordered samling\n    perm <- sample(items)\n    poks <- matrix(0,items,items)\n    subtrees <- list()\n    densFail <- FALSE\n\n    sampleLevel <- function(itemsLeft,x) {\n      if (x == 1)\n        return(itemsLeft)\n      lower <- 1\n      upper <- itemsLeft - (x - 1)\n      if (lower == upper)\n        sampleResult <- lower\n      else\n        sampleResult <- sample(lower:upper,1)\n      c(sampleResult,c(sampleLevel(itemsLeft - sampleResult,x - 1)))\n    }\n\n    for (i in 1:trees) {\n      size.i <- treeSizes[i]\n      levels <- treeDepths[i] + 1\n      levelSizes <-\n        sampleLevel(size.i,levels)[sample(levels)]\n\n      # Skeleton\n      accumLvl <- cumsum(levelSizes)\n\n      up_down <- function(node) {\n        atLevel <- sum(accumLvl < node) + 1\n        result <- sapply(1:size.i, function(x) {\n          xAtLvl <- sum(accumLvl < x) + 1\n          if (xAtLvl == atLevel + 1 | xAtLvl == atLevel - 1)\n            return(TRUE)\n          else\n            return(FALSE)\n        })\n      }\n\n      mark <- rep(TRUE, size.i)\n      mark[sample(size.i,1)] <- FALSE\n\n      while (sum(mark) != 0) {\n        pickFrom <- c(1:size.i)[!mark]\n        if (length(pickFrom) == 1)\n          begin <- pickFrom[1]\n        else\n          begin <- sample(pickFrom,1)\n        avail <- (up_down(begin) & mark)\n        if (sum(avail) == 0) next\n        pickFrom <- c(1:size.i)[avail]\n        if (length(pickFrom) == 1)\n          end <- pickFrom[1]\n        else\n          end <- sample(pickFrom,1)\n        mark[end] <- FALSE\n        poks[perm[min(begin,end)],perm[max(begin,end)]] <- 1\n      }\n\n      if (size.i != 1){\n        groundLvl <- c(0,accumLvl)\n        pNow <- (size.i-1)/sum((c(1,levelSizes)*c(levelSizes,1))[2:levels])\n        if (pNow < 1){\n          p <- (density - pNow)/(1-pNow)\n          if (p < 0) densFail <- TRUE\n          else{\n            # Add random arc\n            for (j in 1:(levels-1))\n              for (k in 1:levelSizes[j])\n                for (m in 1:levelSizes[j+1]){\n                  begin <- perm[groundLvl[j]+k]\n                  end <- perm[groundLvl[j+1]+m]\n                  if (poks[begin,end] == 0)\n                    poks[begin,end] <- sample(0:1,1,prob = c(1-p,p))\n                }\n          }\n        }\n      }\n      # ###############\n      list.i <- perm[1:size.i]\n      tree.i <- as.matrix(poks[list.i,list.i])\n      colnames(tree.i) <- as.character(list.i)\n      rownames(tree.i) <- as.character(list.i)\n      tree.i <- list(tree.i, levelSizes)\n      names(tree.i) <- c(\"matrix\",\"level.sizes\")\n      subtrees <- append(subtrees,list(tree.i))\n\n      perm <- perm[(size.i + 1):length(perm)]\n    }\n\n    colnames(poks) <- as.character(1:items)\n    rownames(poks) <- colnames(poks)\n\n    list(ks = poks, comp = subtrees)\n  }\n\n  nmfComLearn <- function(R, concepts){\n    QSComGen <- function(Q, S){\n      R <- (Q/rowSums(Q)) %*% S\n      R[R >= 0.5] <- 1\n      R[R < 0.5] <- 0\n      return(R)\n    }\n    learn <- nmfLearn(R, concepts = concepts, func = QSComGen)\n    Q <- learn$Q\n    S <- learn$S\n    conceptsDiff <- sapply(1:concepts,function(x){1-mean(S[x,])})\n    list(Q = Q, M = S, concept.exp = conceptsDiff)\n  }\n  nmfConLearn <- function(R, concepts){\n    QSConGen <- function(Q, S){\n      return(0 + !(Q%*%(1-S)))\n    }\n    learn <- nmfLearn(R, concepts = concepts, func = QSConGen)\n    Q <- learn$Q\n    S <- learn$S\n\n    conceptsDiff <- sapply(1:concepts,function(x){1-mean(S[x,])})\n    list(Q = Q, M = S, concept.exp = conceptsDiff)\n  }\n  nmfDisLearn <- function(R, concepts){\n    QSDisGen <- function(Q, S){\n      return(1-!(Q%*%S))\n    }\n    learn <- nmfLearn(R, concepts = concepts, func = QSDisGen)\n    Q <- learn$Q\n    S <- learn$S\n\n    conceptsDiff <- sapply(1:concepts,function(x){1-mean(S[x,])})\n    list(Q = Q, M = S, concept.exp = conceptsDiff)\n  }\n  linAvgLearn <- function(R, concepts){\n    Q <- genQRand(nrow(R), concepts)\n    S <- matrix(0,concepts, ncol(R))\n    space <- genQMax(concepts,concepts)\n    space <- space[sample(1:nrow(space)),]\n\n    learnQ <- function(){\n      ref <- R[iQ,]\n      predict <- QSAvgGenR2(Q = space, S = S)\n      distance <- colSums((t(predict) - ref)^2)\n      best <- which.min(distance)[1]\n      t(space[best,])\n    }\n\n    learnS <- function(){\n      ref <- R[,iS]\n      Qn <- Q/rowSums(Q)\n      # least square est of S squared\n      # Qn %*% S2 ~ R^2 = R\n      S2 <- ginv(Qn) %*% ref\n      #clipping works because the surface is convex\n      S2[S2 > 1] <- 1\n      S2[S2 < 0] <- 0\n      return(sqrt(S2))\n    }\n\n    hault <- 0\n    threshold <- max(nrow(Q), ncol(S))\n    permS <- sample(ncol(S))\n    permQ <- sample(nrow(Q))\n\n    for (i in 1:1000){\n      idS <- (i-1) %% ncol(S) + 1\n      idQ <- (i-1) %% nrow(Q) + 1\n      if (idS == 1) permS <- sample(ncol(S))\n      if (idQ == 1) permQ <- sample(nrow(Q))\n      iS <- permS[idS]\n      iQ <- permQ[idQ]\n\n      lS <- learnS()\n      lQ <- learnQ()\n\n      progress = any(S[,iS]!=lS) | any(Q[iQ,]!=lQ)\n      if (progress == TRUE) hault <- 0\n      else hault <- hault + 1\n      if (hault == threshold) break\n\n      S[,iS] <- learnS()\n      Q[iQ,] <- learnQ()\n    }\n\n    list(Q = Q, S = S)\n  }\n  dinaLearn <- function(R, Q){\n    learn <- din(data = t(R), q.matrix = Q, rule = \"DINA\", progress = FALSE)\n    concepts <- ncol(Q)\n\n    s <- learn$pattern$mle.est\n    S <- sapply(s, function(x){\n      sapply(1:concepts, function(y){\n        as.numeric(substring(x,y,y))\n      })\n    })\n    slip <- learn$slip$est\n    guess <- learn$guess$est\n    skillSpace <- t(learn$attribute.patt.splitted)\n    skillDist <- learn$attribute.patt$class.prob\n\n    list(Q = Q, M = S, skill.space = skillSpace, skill.dist = skillDist, slip = slip, guess = guess)\n  }\n  dinoLearn <- function(R, Q){\n    learn <- din(data = t(R), q.matrix = Q, rule = \"DINO\", progress = FALSE)\n    concepts <- ncol(Q)\n\n    s <- learn$pattern$mle.est\n    S <- sapply(s, function(x){\n      sapply(1:concepts, function(y){\n        as.numeric(substring(x,y,y))\n      })\n    })\n    slip <- learn$slip$est\n    guess <- learn$guess$est\n    skillSpace <- t(learn$attribute.patt.splitted)\n    skillDist <- learn$attribute.patt$class.prob\n\n    list(Q = Q, M = S, skill.space = skillSpace, skill.dist = skillDist, slip = slip, guess = guess)\n  }\n  ks.init <- function(raw, alpha.c, alpha.p, p.min) {\n    student.var <- var(rowMeans(raw))\n    raw <- t(raw)\n    s.less.na <- colSums(!is.na(raw))\n    raw.sum <- colSums(raw, na.rm=T)\n    p <- (raw.sum+1)/(s.less.na+2)\n    odds <- p/(1-p)\n    ans.cp.t <- replace(raw, is.na(raw), 0) # answers for crossprod computations of success\n    ans.cp.f <- round(replace(!raw, is.na(raw), 0)) # answers for crossprod computations of failures\n    ft <- array(c(crossprod(ans.cp.t,ans.cp.t), # frequency table of TT, TF, FT, and FF\n                  # f11, f21, f12, f22\n                  crossprod(ans.cp.t,ans.cp.f),\n                  crossprod(ans.cp.f,ans.cp.t),\n                  crossprod(ans.cp.f,ans.cp.f)),\n                c(ncol(ans.cp.t), ncol(ans.cp.t), 4)) + 1 # Laplace correction of + 1\n    condp.t <- (ft[,,1]) / (ft[,,1]+ft[,,3]) # P(row|col)\n    condp.f <- (ft[,,2]) / (ft[,,2]+ft[,,4]) # P(row|!col)\n    odds.t <- PToOdds(condp.t)\n    odds.f <- PToOdds(condp.f)\n    state=odds\n    #  or <- list(t=odds.t/odds, f=odds.f/odds) # something to try (doesn't get exactly same result)\n    # Start computing interaction test based on approximation of SE of log.odds.ratio : \\sqrt(\\sum_i 1/n_i)\n    log.odds.ratio <- log((ft[,,1] * ft[,,4])/(ft[,,2] * ft[,,3]))\n    log.odds.se <- sqrt((1/ft[,,1] + 1/ft[,,2] + 1/ft[,,3] + 1/ft[,,4]))\n    log.odds.p <- 2 * pnorm(- abs(log.odds.ratio) / log.odds.se) # two-tail test for a normal distribution\n    # log.odds.interaction is a matrix of the pairs that passed the interaction test\n    log.odds.interaction <- (log.odds.p < alpha.c)\n    m.rel <- log.odds.interaction\n    diag(m.rel) <- F\n    # Compute P(B=1|A=1)\n    a1 <- (ft[,,1]+ft[,,3])-2             # substract Laplace correction\n    b1a1 <- (ft[,,1])-1                   # substract Laplace correction\n    # apply binom.test to slots that passed the interaction test\n    p.b1a1.v <- apply(cbind(b1a1[m.rel], a1[m.rel]),\n                      1,              # by row\n                      function(n.k) pbinom(n.k[1], n.k[2], p.min))\n    # p.b1a1.v is a vector and now we need a matrix\n    p.b1a1 <- matrix(F, ncol(m.rel), ncol(m.rel))\n    # Why is this '>' here and below??  Should be corrected by inverting the ratio.\n    p.b1a1[m.rel] <- p.b1a1.v > alpha.p                 # matrix is re-indexed by m\n    # Repeat for p.a0b0 (P(A=0|B=0)\n    # Compute P(A=0|B=0)\n    a0 <- (ft[,,4]+ft[,,3])-2           # substract Laplace correction\n    a0b0 <- (ft[,,4])-1                 # substract Laplace correction\n    p.a0b0.v <- apply(cbind(a0b0[m.rel], a0[m.rel]),\n                      1,              # by row\n                      function(n.k) pbinom(n.k[1], n.k[2], p.min))\n    # p.a0b0.v is a vector and now we need a matrix\n    p.a0b0 <- matrix(F, ncol(m.rel), ncol(m.rel))\n    p.a0b0[m.rel] <- p.a0b0.v  > alpha.p               # matrix is re-indexed by m\n    # The relation matrix is the combination of both tests (given that the interaction test is\n    # already taken into account) and we put it in integer format for backward compatibility.\n    # Transpose is also for backward compatibility\n    m.rel <- t(round(p.a0b0 & p.b1a1))\n    # note: variation qui devrait en theorie etre meilleure mais, en fait, n'apporte aucune difference\n    # condp.t <- t(apply(raw,2,function(c) (colSumsRobust(raw[c==1,])+(2*p))/(raw.sum+2) )) # Kononenko (1991) citant Chestnik (1990)\n    or <- list(t=t(m.rel) * odds.t/odds,      # We only retain odds ratios of links and in the next\n               # instructions we set the others to 1 such that it has\n               # not influence in the computation of new evidence\n               f=m.rel * odds.f/odds)\n    or$t[or$t==0] <- 1                # neutral evidence effect\n    or$f[or$f==0] <- 1                # neutral evidence effect\n    nlinks = colSums(m.rel, na.rm=T) + rowSums(m.rel, na.rm=T)\n    log.nlinks = 0.6931472 / (log((nlinks+1)) + 0.6931472) # 0.6931472 is the entropy of 0.5\n    list(student.var = student.var, avg.success = mean(raw), state = state, or.t = odds.t, or.f = odds.f, po = list(ks = m.rel, comp = NULL),\n         alpha.c = alpha.c, alpha.p = alpha.p, p.min = p.min)\n  }\n  irt2plLearn <- function(R){\n\n    t <- rnorm(ncol(R))\n    a <- rnorm(nrow(R)) # a = -discrimination\n    b <- rnorm(nrow(R)) # b = discrimination * difficulty\n    p <- c(t,a,b) # collective parameter\n\n    sigmoid <- function(param){\n      t <- param[1:ncol(R)]\n      a <- param[(ncol(R)+1):(ncol(R)+nrow(R))]\n      b <- param[(ncol(R)+nrow(R)+1):length(param)]\n      linear <- a%*%t(t) + b%*%t(rep(1,ncol(R)))\n      return(1/(1+exp(linear)))\n    }\n\n    cost <- function(param){\n      s <- sigmoid(param = param)\n      y1 <- log(s)\n      y0 <- log(1-s)\n      return(-sum(R*y1+(1-R)*y0))\n    }\n\n    grad <- function(param){\n      s <- sigmoid(param = param)\n      ga <- colSums(t(s - R)*t)\n      gb <- rowSums(s-R)\n      gt <- colSums((s-R)*a)\n      return(c(gt,ga,gb))\n    }\n\n    learn <- optim(p, cost, grad)\n\n    t <- learn$par[1:ncol(R)]\n    a <- learn$par[(ncol(R)+1):(ncol(R)+nrow(R))]\n    b <- learn$par[(ncol(R)+nrow(R)+1):length(learn$par)]\n\n    abi <- t\n    dis <- -a\n    dif <- b / dis\n\n    list(dis = dis, dif = dif, abi = abi)\n  }\n  expLearn <- function(R){\n    stexp <- colMeans(R)\n    itexp <- rowMeans(R)\n    list (st.exp = stexp, it.exp = itexp)\n  }\n  bktPerItemLearn <- function(R, order){\n    if (is.null(order)) order = rep(1,nrow(R))\n    items <- max(order)\n    students <- ncol(R)\n    probInitS <- matrix(0,items,students)\n    L <- matrix(0,items, students)\n    slip <- matrix(0,items, students)\n    guess <- matrix(0,items, students)\n\n    for (i in 1:items){\n      Ri <- R[which(order == i),]\n      for (j in 1:students){\n        learn <- binaryHMMLearn(Ri[,j])\n        probInitS[i,j] <- learn$probInitS\n        L[i,j] <- learn$L\n        slip[i,j] <- learn$slip\n        guess[i,j] <- learn$guess\n      }\n    }\n    list(S = probInitS, L = L, bkt.slip = slip, bkt.guess = guess,\n         time = nrow(R), order = order, per.item = TRUE, Q = diag(items))\n  }\n  bktPerTestLearn <- function(R){\n    items <- dim(R)[1]\n    students <- dim(R)[2]\n    probInitS <- matrix(0,items,students)\n    L <- matrix(0,items, students)\n    slip <- matrix(0,items, students)\n    guess <- matrix(0,items, students)\n    for (i in 1:items){\n      for (j in 1:students){\n        cat(paste0(\"\\tItem \",toStr(i,items),\" Student \", toStr(j,students),\"\\n\"))\n        learn <- binaryHMMLearn(R[i,j,])\n        probInitS[i,j] <- learn$probInitS\n        L[i,j] <- learn$L\n        slip[i,j] <- learn$slip\n        guess[i,j] <- learn$guess\n      }\n    }\n    list(S = probInitS, L = L, bkt.slip = slip, bkt.guess = guess,\n         time = dim(R)[3], order = NULL, per.item = FALSE, Q = diag(items))\n  }\n  bktBinLearn <- function(R, order){\n    r <- NULL #return this\n    if (length(dim(R)) == 2) return(bktPerItemLearn(R, order))\n    else return(bktPerTestLearn(R))\n  }\n\n  #======================+\n  # Channeling functions |\n  #======================+\n\n  #----------+\n  # Upstream |\n  #----------+\n\n  stexp.itexp.2.exp <- function(x){expGen(x[[1]], x[[2]])}\n  dis.dif.abi.2.irt <- function(x){logitGen(x[[1]],x[[2]],x[[3]])}\n  Q.M.slip.guess.2.dina <- function(x){dinaGen(x[[1]],x[[2]],x[[3]],x[[4]])}\n  Q.M.slip.guess.2.dino <- function(x){dinoGen(x[[1]],x[[2]],x[[3]],x[[4]])}\n  Q.M.2.nmf.con <- function(x){QMConGen(x[[1]],x[[2]])}\n  Q.M.2.nmf.dis <- function(x){QMDisGen(x[[1]],x[[2]])}\n  Q.M.2.nmf.com <- function(x){QMComGen(x[[1]],x[[2]])}\n  #Q.S.2.lin.pes <- function(x){QSLinPesGen(x[[1]],x[[2]])}\n  Q.S.2.lin.avg <- function(x){QSLinAvgGen(x[[1]],x[[2]])}\n  stvar.stu.state.or.po.2.poks <- function(x){\n    Gen.Synthetic.POKS(x[[1]],x[[2]],x[[3]],x[[4]],x[[5]],x[[6]],x[[7]],x[[8]],x[[9]])}\n  st.po.avg.2.poks <- function(x){poksGen(x[[1]],x[[2]],x[[3]],x[[4]],x[[5]],x[[6]])}\n  S.L.slip.guess.time.order.peritem.2.bkt <- function(x){\n    skillBktGen(x[[1]],x[[2]],x[[3]],x[[4]],x[[5]],x[[6]],x[[7]])}\n  S.L.slip.guess.time.order.peritem.Q.mod.2.bkt <- function(x){\n    qBktGen(x[[1]],x[[2]],x[[3]],x[[4]],x[[5]],x[[6]],x[[7]],x[[8]],x[[9]])}\n  time.items.2.order <- function(x){(1:x[[1]] - 1) %% x[[2]] + 1}\n  po.2.state <- function(x){po2State(x[[1]])}\n  stvar.po.2.or.t <- function(x){stVarPo2Ort(x[[1]],x[[2]])}\n  stvar.po.2.or.f <- function(x){stVarPo2Orf(x[[1]],x[[2]])}\n  items.tree.depth.dens.per.2.po <- function(x){\n    genPoks(x[[1]],x[[2]],x[[3]],x[[4]],x[[5]],x[[6]],x[[7]],x[[8]])}\n  items.concepts.2.Q <- function(x){genQRand(x[[1]],x[[2]])}\n  rn <- function(x) {runif(x[[1]],0,1)}\n  rmn <- function(x) {\n    matrix(runif(x[[1]]*x[[2]],0,1),x[[1]],x[[2]])\n  }\n  mean.n.2.vec <- function(x){\n    m <- x[[1]]\n    n <- x[[2]]\n    sapply(1:n, function(x){\n      i <- n-x+1\n      r <- runif(1,max(i*m-(i-1),0),min(i*m,1))\n      m <<- (i*m - r)/(i-1)\n      return(r)\n    })\n  }\n  mean.n.var.2.vec <- function(x){\n    m <- x[[1]]\n    n <- x[[2]]\n    v <- x[[3]]\n    if (v == 0) v <- 1e-10\n    s <- m*(1-m)/v - 1\n    if (s < 0) s <- 0\n    rbeta(n, s*m, s - s*m)\n  }\n  rmean.n.cvar.2.mat <- function(x){\n    n <- x[[2]]\n    v <- x[[3]]\n    if (v == 0) v <- 1e-10\n    t(sapply(x[[1]], function(m){\n      s <- m*(1-m)/v - 1\n      if (s < 0) s <- 0\n      rbeta(n, s*m, s - s*m)\n    }))\n  }\n  con.size.2.skspace <- function(x){\n    concepts <- x[[1]]\n    size <- x[[2]]\n    twoC <- 2^concepts\n    if (size > twoC) stop(\"skill.space.size cannot be larger than 2^concepts\")\n    maxCombn(concepts)[,sample(twoC,size)]\n  }\n  stu.skspace.skdist.2.M <- function(x){\n    x[[2]][,sample(1:length(x[[3]]),size=x[[1]],prob = x[[3]],replace=TRUE)]\n  }\n  stu.conexp.2.M<- function(x){\n    conexp <- x[[2]]\n    sapply(1:x[[1]], function(dum){\n      sapply(conexp, function(p){\n        sample(0:1,1,prob=c(1-p,p))\n      })\n    })\n  }\n\n  #------------+\n  # Downstream |\n  #------------+\n\n  exp.2.stexp.itexp <- function(x){expLearn(x[[1]])}\n  irt.2.dis.dif.abi <- function(x){irt2plLearn(x[[1]])}\n  dina.2.Q.M.space.slip.guess <- function(x){dinaLearn(x[[1]],x[[2]])}\n  dino.2.Q.M.space.slip.guess <- function(x){dinoLearn(x[[1]],x[[2]])}\n  nmf.con.2.Q.M.conexp <- function(x){nmfConLearn(x[[1]],x[[2]])}\n  nmf.dis.2.Q.M.conexp <- function(x){nmfDisLearn(x[[1]],x[[2]])}\n  nmf.com.2.Q.M.conexp <- function(x){nmfComLearn(x[[1]],x[[2]])}\n  lin.avg.2.Q.S <- function(x){linAvgLearn(x[[1]],x[[2]])}\n  poks.learn <- function(x){ks.init(x[[1]],x[[2]],x[[3]],x[[4]])}\n  bkt.bin.learn <- function(x){bktBinLearn(x[[1]],x[[2]])}\n\n  order.2.time.items <- function(x){list(length(x),max(x))}\n  n.row.col <- function(x){list(nrow(x),ncol(x))}\n  n.row.col.rmean <- function(x){list(nrow(x),ncol(x),rowMeans(x))}\n  length.l <- function(x){list(length(x))}\n  mean.length <- function(x){list(mean(x),length(x))}\n  mean.length.var <- function(x){list(mean(x),length(x),var(x))}\n  n.row.col.cvar.rmean <- function(x){list(nrow(x),ncol(x),var(colMeans(x)),rowMeans(x))}\n  skspsize.min.con <- function(x){\n    r <- ceiling(log(x,2))\n    class(r) <- \"min\"\n    list(r)\n  }\n  max.bound.min <- function(x){\n    r <- x\n    class(r) <- \"max\"\n    list(r)\n  }\n\n  #===================================================================================\n  # Definition of node.i has the following syntax:\n  # node.i <- list(S, L, fs, fl)\n  # Where S is a set of nodes that can be infered from node.i\n  # and L = list(set.of.nodes.1, set.of.nodes.2, ...)\n  # set.of.nodes.k is a minimal set of nodes that can sufficiently generate node.i\n  # and fs is a function that maps from node.i to S\n  # and fl is a list of functions that map respective sets in L to node.i\n  #\n  # e.g.\n  # state. <- list(c(\"items\"), list(c(\"po\",\"items\")), fs, fl)\n  # then node state can be generated from po and items by fs\n  # and items can be infered from state by fl\n  #===================================================================================\n\n  #------------+\n  # root nodes |\n  #------------+\n\n  # root nodes to prevent conflicts and detect insufficiency\n  root. <- list(NULL, list(NULL), NULL, list(NULL))\n  items. <- root.\n  students. <- root.\n  concepts. <- root.\n  init.vals. <- root.\n\n  # root nodes with predefined default values initialized only when needed\n  bkt.guess.st.var. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"bkt.guess.st.var\"]]}))\n  bkt.slip.st.var. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"bkt.slip.st.var\"]]}))\n  S.st.var. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"S.st.var\"]]}))\n  L.st.var. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"L.st.var\"]]}))\n  abi.mean. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"abi.mean\"]]}))\n  abi.sd. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"abi.sd\"]]}))\n  alpha.c. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"alpha.c\"]]}))\n  alpha.p. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"alpha.p\"]]}))\n  p.min. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"p.min\"]]}))\n  bkt.mod. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"bkt.mod\"]]}))\n  min.ntree. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"min.ntree\"]]}))\n  min.depth. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"min.depth\"]]}))\n  min.it.per.tree. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"min.it.per.tree\"]]}))\n  density. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"density\"]]}))\n  per.item. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"per.item\"]]}))\n  avg.success. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"avg.success\"]]}))\n  student.var. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"student.var\"]]}))\n  time. <- list(NULL, list(c(\"init.vals\")), NULL, list(function(x){x[[1]][[\"time\"]]}))\n\n  #--------------------------------------------------------------------------+\n  # leaf nodes, correspond to a dataset in regard of the respective model    |\n  # Third entries in the below leaf nodes are supposed to be learn functions |\n  #--------------------------------------------------------------------------+\n\n  exp. <- list(c(\"st.exp\",\"it.exp\"), list(c(\"st.exp\",\"it.exp\")),\n               exp.2.stexp.itexp, list(stexp.itexp.2.exp))\n  irt. <- list(c(\"dis\",\"dif\",\"abi\"), list(c(\"dis\",\"dif\",\"abi\")),\n               irt.2.dis.dif.abi, list(dis.dif.abi.2.irt))\n  dina. <- list(c(\"Q\",\"M\",\"skill.space\",\"skill.dist\",\"slip\",\"guess\"), list(c(\"Q\",\"M\",\"slip\",\"guess\")),\n                dina.2.Q.M.space.slip.guess, list(Q.M.slip.guess.2.dina))\n  dino. <- list(c(\"Q\",\"M\",\"skill.space\",\"skill.dist\",\"slip\",\"guess\"), list(c(\"Q\",\"M\",\"slip\",\"guess\")),\n                dino.2.Q.M.space.slip.guess, list(Q.M.slip.guess.2.dino))\n  nmf.con. <- list(c(\"Q\",\"M\",\"concept.exp\"), list(c(\"Q\",\"M\")),\n                   nmf.con.2.Q.M.conexp, list(Q.M.2.nmf.con))\n  nmf.dis. <- list(c(\"Q\",\"M\",\"concept.exp\"), list(c(\"Q\",\"M\")),\n                   nmf.dis.2.Q.M.conexp, list(Q.M.2.nmf.dis))\n  nmf.com. <- list(c(\"Q\",\"M\",\"concept.exp\"), list(c(\"Q\",\"M\")),\n                   nmf.com.2.Q.M.conexp, list(Q.M.2.nmf.com))\n  #lin.pes. <- list(NULL, list(c(\"Q\",\"S\")), NULL, list(Q.S.2.lin.pes))\n  lin.avg. <- list(c(\"Q\",\"S\"), list(c(\"Q\",\"S\")),\n                   lin.avg.2.Q.S, list(Q.S.2.lin.avg))\n  poks.<- list(c(\"student.var\",\"avg.success\",\"state\",\"or.t\",\"or.f\",\"po\",\"alpha.c\",\"alpha.p\",\"p.min\"),\n               list(c(\"student.var\", \"students\", \"state\", \"or.t\",\"or.f\",\"po\",\"alpha.c\",\"alpha.p\",\"p.min\"),\n                    c(\"students\",\"po\",\"avg.success\",\"alpha.c\",\"alpha.p\",\"p.min\")),\n               poks.learn, list(stvar.stu.state.or.po.2.poks,\n                                st.po.avg.2.poks))\n  bkt. <- list(c(\"S\",\"L\",\"bkt.slip\",\"bkt.guess\",\"time\",\"order\",\"per.item\",\"Q\"),\n               list(c(\"S\",\"L\",\"bkt.slip\",\"bkt.guess\",\"time\",\"order\",\"per.item\"),\n                    c(\"S\",\"L\",\"bkt.slip\",\"bkt.guess\",\"time\",\"order\",\"per.item\",\"Q\",\"bkt.mod\")),\n               bkt.bin.learn, list(S.L.slip.guess.time.order.peritem.2.bkt,\n                                   S.L.slip.guess.time.order.peritem.Q.mod.2.bkt))\n\n  #--------------------+\n  # Intermediate nodes |\n  #--------------------+\n\n  bkt.slip.it.exp. <- list(c(\"items\"), list(c(\"items\")),\n                           length.l, list(rn))\n  bkt.guess.it.exp. <- list(c(\"items\"), list(c(\"items\")),\n                            length.l, list(rn))\n  S.con.exp. <- list(c(\"concepts\"), list(c(\"concepts\")), length.l, list(rn))\n  L.con.exp. <- list(c(\"concepts\"), list(c(\"concepts\")), length.l, list(rn))\n  skill.space. <- list(c(\"concepts\",\"skill.space.size\"), list(c(\"concepts\",\"skill.space.size\")),\n                       n.row.col, list(con.size.2.skspace))\n\n  skill.space.size. <- list(c(\"concepts\"), list(c(\"concepts\")), skspsize.min.con,\n                            list(function(x){2^x[[1]]}))\n  skill.dist. <- list(c(\"skill.space.size\"),list(c(\"skill.space.size\")),\n                      length.l, list(function(x){rep(1/x[[1]],x[[1]])}))\n  concept.exp. <- list(c(\"concepts\"),list(c(\"concepts\")),length.l,list(rn))\n  st.exp. <- list(c(\"avg.success\",\"students\",\"student.var\"),\n                  list(c(\"avg.success\",\"students\",\"student.var\")),\n                  mean.length.var, list(mean.n.var.2.vec))\n  it.exp. <- list(c(\"avg.success\",\"items\"), list(c(\"avg.success\",\"items\")),\n                  mean.length, list(mean.n.2.vec))\n  max.ntree. <- list(c(\"min.ntree\"), list(c(\"items\")),\n                     max.bound.min, list(function(x){x[[1]]}))\n  max.depth. <- list(c(\"min.depth\"), list(c(\"items\")),\n                     max.bound.min, list(function(x) {x[[1]]-1}))\n  max.it.per.tree. <- list(c(\"min.it.per.tree\"), list(c(\"items\")),\n                           max.bound.min, list(function(x) {x[[1]]}))\n\n  dis. <- list(c(\"items\"), list(c(\"items\")),\n               length.l, list(rn))\n  dif. <- list(c(\"items\"), list(c(\"items\")),\n               length.l, list(rn))\n  abi. <- list(c(\"students\",\"abi.mean\",\"abi.sd\"),\n               list(c(\"students\"),c(\"students\",\"abi.mean\",\"abi.sd\")),\n               function(x){list(length(x), mean(x), sd(x))},\n               list(rn,function(x){rnorm(x[[1]],mean=x[[2]],sd=x[[3]])}))\n  state. <- list(c(\"items\"), list(c(\"po\")),\n                 length.l, list(po.2.state))\n  or.t. <- list(c(\"items\",\"items\"), list(c(\"student.var\",\"po\")),\n                n.row.col, list(stvar.po.2.or.t))\n  or.f. <- list(c(\"items\",\"items\"), list(c(\"student.var\",\"po\")),\n                n.row.col, list(stvar.po.2.or.f))\n  po. <- list(c(\"items\",\"items\"), list(c(\"items\",\"min.ntree\",\"max.ntree\",\n                                         \"min.depth\",\"max.depth\",\"density\",\n                                         \"min.it.per.tree\",\"max.it.per.tree\")),\n              function(x){list(nrow(x$ks),ncol(x$ks))},\n              list(items.tree.depth.dens.per.2.po))\n  slip. <- list(c(\"items\"), list(c(\"items\")),\n                length, list(rn))\n  guess. <- list(c(\"items\"), list(c(\"items\")),\n                 length, list(rn))\n  Q. <- list(c(\"items\",\"concepts\"), list(c(\"items\",\"concepts\")),\n             n.row.col, list(items.concepts.2.Q))\n  S. <- list(c(\"concepts\",\"students\",\"S.st.var\",\"S.con.exp\"),\n             list(c(\"concepts\",\"students\"),c(\"S.con.exp\",\"students\",\"S.st.var\")),\n             n.row.col.cvar.rmean, list(rmn, rmean.n.cvar.2.mat))\n  M. <- list(c(\"concepts\",\"students\",\"concept.exp\"),\n             list(c(\"S\"),c(\"students\",\"skill.space\",\"skill.dist\"),\n                  c(\"students\",\"concept.exp\")),\n             n.row.col.rmean, list(function(x){round(x[[1]])},\n                                   stu.skspace.skdist.2.M,\n                                   stu.conexp.2.M))\n  L. <- list(c(\"concepts\",\"students\",\"L.st.var\",\"L.con.exp\"),\n             list(c(\"concepts\",\"students\"),c(\"L.con.exp\",\"students\",\"L.st.var\")),\n             n.row.col.cvar.rmean, list(rmn, rmean.n.cvar.2.mat))\n  bkt.slip. <- list(c(\"items\",\"students\",\"bkt.slip.st.var\",\"bkt.slip.it.exp\"),\n                    list(c(\"items\",\"students\"),c(\"bkt.slip.it.exp\",\"students\",\"bkt.slip.st.var\")),\n                    n.row.col.cvar.rmean, list(rmn, rmean.n.cvar.2.mat))\n  bkt.guess. <- list(c(\"items\",\"students\",\"bkt.guess.st.var\",\"bkt.guess.it.exp\"),\n                     list(c(\"items\",\"students\"),c(\"blt.guess.it.exp\",\"students\",\"bkt.guess.st.var\")),\n                     n.row.col.cvar.rmean, list(rmn, rmean.n.cvar.2.mat))\n  order. <- list(c(\"time\",\"items\"), list(c(\"time\",\"items\")),\n                 order.2.time.items, list(time.items.2.order))\n  r <-\n    list(exp = exp., irt = irt., poks = poks., dina = dina.,\n         dino = dino., nmf.con = nmf.con.,\n         nmf.com = nmf.com., nmf.dis = nmf.dis.,\n         #lin.pes\n         lin.avg = lin.avg., bkt = bkt., abi.mean = abi.mean., abi.sd = abi.sd.,\n         dis = dis., dif = dif., abi = abi., st.exp = st.exp., it.exp = it.exp.,\n         state = state., avg.success = avg.success.,\n         student.var = student.var., po = po., or.t = or.t., or.f = or.f.,\n         alpha.p = alpha.p., alpha.c = alpha.c., p.min = p.min.,\n         items = items., students = students., concepts = concepts.,\n         slip = slip., guess = guess.,\n         Q = Q., S = S., M = M., L = L.,\n         S.st.var = S.st.var., S.con.exp = S.con.exp.,\n         L.st.var = L.st.var., L.con.exp = L.con.exp.,\n         skill.space.size = skill.space.size., skill.space = skill.space.,\n         skill.dist = skill.dist., concept.exp = concept.exp.,\n         bkt.slip = bkt.slip., bkt.guess = bkt.guess.,\n         bkt.slip.it.exp = bkt.slip.it.exp., bkt.slip.st.var = bkt.slip.st.var.,\n         bkt.guess.it.exp = bkt.guess.it.exp., bkt.guess.st.var = bkt.guess.st.var.,\n         time = time., bkt.mod = bkt.mod.,\n         per.item = per.item., order = order.,\n         min.ntree = min.ntree., max.ntree = max.ntree., min.depth = min.depth.,\n         max.depth = max.depth., min.it.per.tree = min.it.per.tree.,\n         max.it.per.tree = max.it.per.tree., density = density.,\n         init.vals = init.vals.)\n  sapply(1:length(r), function(x){names(r[[x]]) <<- c(\"tell\",\"gen\",\"f.tell\",\"f.gen\")})\n  return(r)\n}\n\n#' @export\nSTRUCTURE <- assemble.structure()\n\n#===========+\n# CONSTANTS |\n#===========+\n\n#' @export\nALL.MODELS <- c(\"exp\", \"irt\", \"poks\", \"dina\", \"dino\",\n                #\"lin.pes\",\n                \"lin.avg\",\"nmf.con\", \"nmf.dis\", \"nmf.com\", \"bkt\")\n\n#' @export\nKEEP <- list(exp = c(\"avg.success\",\"it.exp\",\"student.var\"),\n             irt = c(\"dis\",\"dif\",\"abi.mean\",\"abi.sd\"),\n             poks = c(\"po\",\"avg.success\",\"alpha.c\",\"alpha.p\",\"p.min\"),\n             dina = c(\"Q\",\"skill.space\",\"skill.dist\",\"slip\",\"guess\"),\n             dino = c(\"Q\",\"skill.space\",\"skill.dist\",\"slip\",\"guess\"),\n             lin.avg = c(\"Q\", \"S.st.var\", \"S.con.exp\"),\n             nmf.con = c(\"Q\", \"concept.exp\"),\n             nmf.dis = c(\"Q\", \"concept.exp\"),\n             nmf.com = c(\"Q\", \"concept.exp\"),\n             bkt = c(\"S.st.var\",\"S.con.exp\",\"L.st.var\",\"L.con.exp\",\n                     \"bkt.slip.st.var\",\"bkt.slip.it.exp\",\n                     \"bkt.guess.st.var\",\"bkt.guess.it.exp\",\n                     \"time\",\"order\",\"per.item\",\"Q\"))\n\n#' @export\nINTEGER <- c(\"items\",\"students\",\"concepts\",\"time\",\"skill.space.size\",\n             \"min.ntree\",\"max.ntree\",\"min.depth\",\"max.depth\",\n             \"min.it.per.tree\",\"max.it.per.tree\")\n\n#' @export\nDEFINITE <- c(\"items\",\"students\",\"concepts\",\"time\",\n              \"skill.space.size\", \"avg.success\")\n\n#' @export\nBOUND.CLASSES <- c(\"min\", \"max\")\n\n#=====================+\n# OPERATING FUNCTIONS |\n#=====================+\n\n#-----------------------------------------------------------------------------+\n# argument pars stands for a list of all parameters across all models         |\n# It is meant to be produced and updated by the function pars()               |\n# down.stream(), and upstream() are general purpose functions                 |\n# that will be used as building blocks for functions at user-interface level  |\n#-----------------------------------------------------------------------------+\n\n#-----------------------------------------------------------------------------+\n# down.stream() propagates all obtainable info through type-1 connection      |\n# in the STRUCTURE, also checks for conflicts.                                |\n# up.stream() propagates info through type-2 connection in the STRUCTURE,     |\n# the propagation is tailored so that a specified target can be calculated    |\n#-----------------------------------------------------------------------------+\n\n#' Propagate information downwards\n#'\n#' This function takes the available parameters and try to learn all\n#' possible parameters at lower level, simultaneously check for conflicts\n#'\n#' @param pars an object of \\code{context} class describes all available information in current context\n#' @return a new \\code{context} object obtained from the input\n#' @author Hoang-Trieu Trinh\n#' @details\n#' This function use breadth-first scheme to propagate information in\n#' the STRUCTURE, using the learning functions indicated in 3rd element\n#' of each node inside STRUCTURE to learn the corresponding values of\n#' nodes indicated in the 1st element\n#' @export\ndown.stream <- function(pars){\n  curr <- names(pars)[which(sapply(pars,is.null) == 0)]\n\n  # breadth-first propagating\n  while(length(curr) > 0){\n    new <- NULL\n    for (i in 1:length(curr)){\n      var.name <- curr[i]\n      var.val <- pars[[var.name]]\n      child.names <- STRUCTURE[[var.name]][[1]]\n      if (is.null(child.names)) next\n      child.val <- STRUCTURE[[var.name]][[3]](var.val)\n\n      child.not.null <- which(sapply(child.val, function(x){is.null(x)})==0)\n      child.names <- child.names[child.not.null]\n      child.val <- child.val[child.not.null]\n\n      for (j in 1:length(child.names)){\n        child.j.val <- pars[[child.names[j]]]\n        if (!is.null(child.j.val) &\n            ((child.names[j] %in% DEFINITE) |\n             (class(child.val[[j]]) %in% BOUND.CLASSES))){\n          if (!suppressWarnings(compat(child.j.val,child.val[[j]]))){\n            if (class(child.val[[j]]) %in% BOUND.CLASSES)\n              stop(paste0(\"'\", child.names[j],\"' violates bound suggested by '\",var.name,\"'\"))\n            else\n              stop(paste0(\"'\", child.names[j],\"' receives different values at once\"))\n          }\n        }\n        else\n          if (all(class(child.val[[j]]) != BOUND.CLASSES))\n            pars[[child.names[j]]] <- child.val[[j]]\n      }\n      child.not.bound <-\n        which(sapply(child.val,\n                     function(x){class(x) %in% BOUND.CLASSES}) == 0)\n      new <- c(new, child.names[child.not.bound])\n    }\n    curr <- unique(new)\n  }\n  pars\n}\n\n#' Propagate information upwards\n#'\n#' This function takes the available parameters and generate higher\n#' level parameters in a tailored direction so that a specified\n#' target can be reach\n#'\n#' @param target a character string indicates the target's name\n#' @param pars an object of \\code{context} class describes all available information in current context\n#' @param progress a boolean value indicates if the generating process should be printed\n#' @return a new \\code{context} object obtained from the input, if the target cannot be reach,\n#' the old \\code{context} object is returned\n#' @author Hoang-Trieu Trinh\n#' @details\n#' This function runs a recursive search for available information at lower level\n#' nodes in the STRUCTURE that has been provided by the input. Whenever there is\n#' more than two ways to generate a parameter, the function chooses the one that\n#' requires inputs that is more likely to be learned directly from the target.\n#' @seealso \\code{which.closest}\n#' @export\nup.stream <- function(target, pars, progress = FALSE){\n\n  miss <- NULL\n  new.pars <- pars\n  trace <- list(NULL)\n  track <- list(NULL)\n  fill <- FALSE\n\n  check.track <- function(node.name){\n\n    if (!is.null(new.pars[[node.name]])) return(TRUE)\n    gen.methods <- STRUCTURE[[node.name]]$gen\n    if (is.null(unlist(gen.methods))) {\n      if (is.null(miss)) miss <<- node.name\n      return(FALSE)\n    }\n\n    or. <- sapply(gen.methods, function(x){\n      prod(sapply(x,check.track)) # products are equivalent to AND-gate.\n    })\n\n    avail <- which(or. == 1)\n    if (length(avail) == 0) {\n      if (is.null(miss)) miss <<- node.name\n      return(FALSE)\n    }\n    if (length(avail) == 1) pick <- avail\n    else pick <- avail[which.closest(target, gen.methods[avail])]\n\n    track[[node.name]] <<- pick\n    trace[[node.name]] <<- gen.methods[[pick]]\n    return(TRUE)\n  }\n  follow <- function(node.name){\n    node <- STRUCTURE[[node.name]]\n    pick <- track[[node.name]]\n    if (!is.null(pick)){ #which means, node already has a value\n      gen.method <- node$gen[[pick]]\n      if (identical(gen.method,\"init.vals\"))\n        new.pars[[node.name]] <<- node$f.gen[[1]](list(new.pars$init.vals))\n      else {\n        dummy <- sapply(gen.method, follow)\n        if (fill == TRUE)\n          new.pars[[node.name]] <<- node$f.gen[[pick]](new.pars[gen.method])\n      }\n    }\n    return(NULL)\n  }\n\n  success <- check.track(target)\n  if (success == FALSE){\n    message(paste0(\"Cannot reach '\", target,\"' since '\", miss, \"' is missing\"))\n    return(pars)\n  }\n  else{\n    dummy <- follow(target)\n    new.pars <- down.stream(new.pars)\n    fill <- TRUE\n    dummy <- follow(target)\n    if (progress == TRUE & length(trace) > 1){\n      print.trace <- function(node){\n        if (is.null(trace[[names(node)]])) return(NULL)\n        cat(paste0(\"Generate \",names(node),\" from \", node,\"\\n\"))\n        child <- trace[names(node)]\n        trace[[names(node)]] <<- NULL\n        for (i in 1:length(child[[1]])){\n          print.trace(trace[child[[1]][i]])\n        }\n      }\n      print.trace(trace[target])\n    }\n    return(new.pars)\n  }\n}\n\n#-------------------------------+\n# User Interface's sub-routines |\n#-------------------------------+\n\n#' @export\nkeep <- function(model){\n  KEEP[[model]]\n}\n\n#' This function is so lame I cant take it\n#'\n#' @importFrom diagram plotmat\n#' @export\nviz <- function(po){\n  n <- length(po$comp)\n  n.row <- floor(sqrt(n))\n  n.col <- ceiling(n/n.row)\n  par(mfrow = c(n.row, n.col))\n  for (i in 1:n){\n    comp.i <- po$comp[[i]]\n    plotmat(comp.i$matrix,\n            pos = comp.i$level.sizes,\n            lwd = 0.1,\n            arr.type = \"triangle\",\n            curve = 0,\n            box.size = 0.04,\n            box.type = \"round\",\n            endhead = TRUE,\n            arr.pos = 0.85,\n            shadow.size = 0,\n            cex.txt = 0)\n  }\n}\n\n#' @export\ninit <- function(student.var = 1/12, avg.success = 0.5, time = 50,\n                 S.st.var = 1/12, L.st.var = 1/12,\n                 bkt.slip.st.var = 1/12, bkt.guess.st.var = 1/12,\n                 min.ntree = 1, min.depth = 0, min.it.per.tree = 1,\n                 per.item = FALSE, bkt.mod = \"dina\", density = 0.5,\n                 alpha.c = 0.25, alpha.p = 0.25, p.min = 0.5,\n                 abi.mean = 0, abi.sd = 1){\n  as.list(environment())\n}\n\n#==========================+\n# USER INTERFACE FUNCTIONS |\n#==========================+\n\n#' Create or update a context\n#'\n#' This function allows user input a set of parameters to a new or available context\n#'\n#' @param old.pars an object of \\code{context} class describe the context that needed to be updated,\n#' leave this parameter if the user need a new context.\n#' @return an object of \\code{context} class describe the updated or new context\n#' @author Hoang-Trieu Trinh\n#' @details\n#' This function takes in a set of parameters that the user input and assemble them\n#' into a \\code{context} object, it uses the \\code{down.stream} function to check for conflicts\n#' @seealso \\code{down.stream}\n#' @export\n\npars <- function(old.pars = NULL,\n                 init.vals = init(),\n                 dis = NULL, dif = NULL, abi = NULL,\n                 abi.mean = NULL, abi.sd = NULL,\n                 st.exp = NULL, it.exp = NULL,\n                 items = NULL, concepts = NULL, students = NULL,\n                 state = NULL, po = NULL, or.t = NULL, or.f = NULL,\n                 student.var = NULL, avg.success = NULL,\n                 min.ntree = NULL, max.ntree = NULL,\n                 min.depth = NULL, max.depth = NULL, density = NULL,\n                 min.it.per.tree = NULL, max.it.per.tree = NULL,\n                 alpha.c= NULL, alpha.p= NULL, p.min= NULL,\n                 slip = NULL, guess = NULL, per.item = NULL, order = NULL,\n                 Q = NULL, S = NULL, M = NULL, L = NULL, bkt.mod = NULL,\n                 S.st.var = NULL, S.con.exp = NULL,\n                 L.st.var = NULL, L.con.exp = NULL,\n                 skill.space.size = NULL, skill.space = NULL,\n                 skill.dist = NULL, concept.exp = NULL,\n                 bkt.slip = NULL, bkt.guess = NULL, time = NULL,\n                 bkt.slip.it.exp = NULL, bkt.slip.st.var = NULL,\n                 bkt.guess.it.exp = NULL, bkt.guess.st.var = NULL,\n                 irt = NULL, exp = NULL, dina = NULL, dino = NULL,\n                 nmf.con = NULL, nmf.dis = NULL, nmf.com = NULL,\n                 lin.pes = NULL, lin.avg = NULL, poks = NULL, bkt = NULL){\n  new.pars <- NULL #return this.\n  if (!is.null(old.pars)) {\n    if (!identical(class(old.pars),c(\"context\",\"list\")))\n      stop(\"'old.pars' is not an object of the 'context' class\")\n    new.pars <- old.pars\n    update <- as.list(environment())\n    update <- update[3:length(update)]\n    update <- update[which(sapply(update,is.null) == 0)]\n    new.pars[names(update)] <- update\n  }\n  else {\n    new.pars <- as.list(environment())\n    sapply(INTEGER, function(x){\n      if (!is.null(new.pars[[x]]))\n        new.pars[[x]] <<- as.integer(new.pars[[x]])\n    })\n    new.pars <- new.pars[3:length(new.pars)]\n    class(new.pars) <- c(\"context\",class(new.pars))\n  }\n  if (class(new.pars$po) == \"matrix\")\n    new.pars$po <- list(ks = new.pars$po, comp = NULL)\n  down.stream(new.pars)\n}\n\n#' Get a parameter from the current context\n#'\n#' This function generate (if needed) the required target from a context\n#'\n#' @param target a character string indicates the target's name\n#' @param pars an object of \\code{context} class describes the given context\n#' @param progress a boolean value indicates if the generating process should be printed or not\n#' @return if success, a list with two components\n#' \\item{value}{value of the target}\n#' \\item{context}{the corresponding context}\n#' if not success, NULL\n#' @author Hoang-Trieu Trinh\n#' @details\n#' This function uses \\code{up.stream} function to obtain target's value and context\n#' @seealso \\code{up.stream}\n#' @export\nget.par <- function(target, pars, progress = FALSE){\n  g <- up.stream(target, pars, progress)\n  if (!is.null(g)) {\n    ret <- list(g[[target]], g)\n    names(ret) <- c(\"value\", \"context\")\n    return(ret)\n  }\n  else return(NULL)\n}\n\n#' Generate data for a model\n#'\n#' This function does something\n#'\n#' @param model a param\n#' @param pars another param\n#' @param n another param\n#' @param progress another one\n#' @return whatever it is\n#' @author Hoang-Trieu Trinh\n#' @details more detail huh?\n#' @seealso what?\n#' @export\ngen <- function(model, pars, n = 1, progress = FALSE){\n\n  if (!(model %in% ALL.MODELS))\n    stop(paste0(\"Model '\",model,\"' is not available\"))\n  if (!identical(class(pars),c(\"context\",\"list\")))\n    stop(paste0(\"'pars' is of an invalid class\"))\n\n  r <-\n    sapply(1:n,function(x){\n      if (x > 1) progress <- FALSE\n      trial <- up.stream(model, pars, progress)\n      if (is.null(trial))\n        stop(paste0(\"Insufficient information to generate '\",model,\"'\"))\n      list(trial)\n    })\n\n  if (n > 1) return(r) else return(r[[1]])\n}\n\n#' Generate data for a set of models\n#'\n#' This function does something\n#'\n#' @param model a param\n#' @param pars another param\n#' @param n another param\n#' @param progress another one\n#' @return whatever it is\n#' @author Hoang-Trieu Trinh\n#' @details more detail huh?\n#' @seealso what?\n#' @export\ngen.apply <- function(models, pars, multiply = TRUE, n = 1, progress = FALSE){\n\n  result <- NULL #return this\n  if (identical(class(pars),c(\"context\",\"list\"))) pars <- list(pars)\n  else if (class(pars) != \"list\") stop(paste0(\"'pars' is of an invalid class\"))\n\n  # name all the contexts\n  if (is.null(names(pars)))\n    names(pars) <- sapply(1:length(pars), function(x){\n      paste0(\"p\",toStr(x,length(pars)))\n    })\n  else{\n    anony.context <- which(names(pars) == \"\")\n    num.ac <- length(anony.context)\n    names(pars)[anony.context] <- sapply(1:num.ac, function(x){\n      paste0(\"p\",toStr(x,num.ac))\n    })\n  }\n\n  if (multiply == FALSE){\n    suppressWarnings(\n      result <- as.matrix(mapply(function(x,y){\n        gen(x, y, n = n, progress)\n      },models, pars))\n    )\n    if (length(pars) == 1) result <- t(result)\n    rownames(result) <- sapply(1:n, function(x){toStr(x,n)})\n    suppressWarnings(\n      colnames(result) <- mapply(function(x,y){\n        paste(x,y,sep=\".\")\n      }, models, names(pars))\n    )\n  } else {\n    result <- as.matrix(sapply(models,function(x){\n      sapply(pars, function(y){\n        list(gen(x, y, n = n, progress))\n      })\n    }))\n    if (length(pars) == 1) result <- t(result)\n    colnames(result) <- models\n    rownames(result) <- names(pars)\n  }\n\n  t(result)\n}\n\n#' Learn the most probable context for a given data\n#'\n#' This function does something\n#'\n#' @param model a param\n#' @param pars another param\n#' @param n another param\n#' @param progress another one\n#' @return whatever it is\n#' @author Hoang-Trieu Trinh\n#' @details more detail huh?\n#' @seealso what?\n#' @export\nlearn <- function(model, data){\n\n  if (!(model %in% ALL.MODELS))\n    stop(paste0(\"Model '\",model,\"' is not available\"))\n\n  cat(paste0(\"Learning by '\",model,\"' ...\\n\"))\n\n  learned.p <- pars()\n  learned.p[[model]] <- data\n  down.stream(learned.p)\n}\n\n#' Generate synthetic data from a given data\n#' This function does something\n#'\n#' @param model a param\n#' @param pars another param\n#' @param n another param\n#' @param progress another one\n#' @return whatever it is\n#' @author Hoang-Trieu Trinh\n#' @details more detail huh?\n#' @seealso what?\n#' @export\nsyn <- function(model, data, keep.pars = keep(model),\n                students = ncol(data$R), n = 1, progress = FALSE){\n  learned.pars <- learn(model,data)\n  filtered.pars <- pars(students = students)\n  filtered.pars[keep.pars] <- learned.pars[keep.pars]\n  filtered.pars <- down.stream(filtered.pars)\n  list(data = data, synthetic = gen(model, filtered.pars, n = n, progress))\n}\n",
    "created" : 1440992872435.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1565123589",
    "id" : "5AD1FED",
    "lastKnownWriteTime" : 1441270159,
    "path" : "D:/github/edmsyn/R/structure.R",
    "project_path" : "R/structure.R",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}